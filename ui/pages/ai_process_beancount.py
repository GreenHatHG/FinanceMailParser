"""
AI æ™ºèƒ½å¤„ç† Beancount è´¦å•ï¼ˆui_plan.md 2.7ï¼‰

åŠŸèƒ½ï¼š
- è‡ªåŠ¨é€‰æ‹©æœ€æ–° Beancount æ–‡ä»¶ï¼ˆoutputs/beancountï¼‰
- æ”¯æŒå¤šé€‰å†å²è´¦å•ï¼ˆå·²å¡«å……è´¦æˆ·ï¼‰
- è‡ªåŠ¨æ„å»ºå¹¶é¢„è§ˆ Promptï¼ˆé»˜è®¤è„±æ•ï¼‰
- å‘é€å‰ Prompt è„±æ•æ£€æŸ¥ï¼ˆé‡‘é¢ï¼‰
- è°ƒç”¨ AI å¡«å……è´¦æˆ· + å¯¹è´¦ + æ¢å¤é‡‘é¢ + ä¸‹è½½
"""

from __future__ import annotations

from datetime import datetime
from pathlib import Path
import hashlib
import json

import streamlit as st

from constants import BEANCOUNT_OUTPUT_DIR, PROJECT_ROOT
from utils.beancount_file_manager import scan_beancount_files
from utils.beancount_file_manager import read_beancount_file
from utils.amount_masking import AmountMasker
from utils.prompt_redaction_check import check_prompt_redaction
from utils.prompt_builder_v2 import build_smart_ai_prompt, calculate_prompt_stats_v2
from utils.beancount_validator import reconcile_beancount, BeancountReconciler


st.set_page_config(page_title="AI å¤„ç† Beancount", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– AI æ™ºèƒ½å¤„ç† Beancount è´¦å•")
st.write("é€‰æ‹©éœ€è¦ç»™ AI å¡«å……çš„è´¦å•ä¸ï¼ˆå¯é€‰ï¼‰å†å²å‚è€ƒæ–‡ä»¶ï¼Œå·¥å…·å°†è‡ªåŠ¨æ„å»º Promptï¼Œå¹¶å‘é€ç»™ AI å¡«å……æ¶ˆè´¹è´¦æˆ·ã€‚")
st.divider()
MASK_MAP_DIR = PROJECT_ROOT / "outputs" / "mask_maps"


def _format_metric_delta(current: int | float, previous: int | float | None) -> str | None:
    if previous is None:
        return None
    try:
        current_f = float(current)
        previous_f = float(previous)
    except Exception:
        return None

    delta = current_f - previous_f
    if abs(delta) < 1e-9:
        return "0"

    if float(current).is_integer() and float(previous).is_integer():
        return f"{int(delta):+,.0f}"
    return f"{delta:+.2f}"


def _normalize_model_for_token_count(provider: str | None, model: str | None) -> str | None:
    """
    litellm.token_counter çš„ model è¯†åˆ«æ›´å€¾å‘äºâ€œåŸºç¡€æ¨¡å‹åâ€ï¼ˆå¦‚ gpt-4oï¼‰ï¼Œè€Œéå¸¦è·¯ç”±å‰ç¼€ï¼ˆå¦‚ openai/gpt-4oï¼‰ã€‚

    è¿™é‡Œåªå¯¹å·²çŸ¥ provider å‰ç¼€åšå»é™¤ï¼›custom provider ä¸åšå¤„ç†ï¼Œä»¥å…ç ´åè¯¸å¦‚ HuggingFace çš„ "org/model" å½¢å¼ã€‚
    """
    if not model:
        return None
    model = model.strip()
    provider = (provider or "").strip()
    if not provider:
        return model

    if provider in {"openai", "gemini", "anthropic", "azure"}:
        prefix = f"{provider}/"
        if model.startswith(prefix):
            return model[len(prefix):]
    return model


def _decode_uploaded_beancount(raw: bytes) -> str | None:
    if raw is None:
        return None
    try:
        return raw.decode("utf-8")
    except UnicodeDecodeError:
        try:
            return raw.decode("utf-8-sig")
        except Exception:
            return None


@st.cache_data(show_spinner=False)
def _cached_read_beancount_file(path_str: str, mtime: float) -> str | None:
    # mtime ä½œä¸ºç¼“å­˜ key çš„ä¸€éƒ¨åˆ†ï¼Œæ–‡ä»¶å˜æ›´æ—¶è‡ªåŠ¨å¤±æ•ˆ
    return read_beancount_file(Path(path_str))


all_files = scan_beancount_files(BEANCOUNT_OUTPUT_DIR) if BEANCOUNT_OUTPUT_DIR.exists() else []


st.subheader("AI å¤„ç†çš„è´¦å•")

if not BEANCOUNT_OUTPUT_DIR.exists():
    st.warning("æœªæ‰¾åˆ° outputs/beancount ç›®å½•ï¼šä½ ä»ç„¶å¯ä»¥ä¸Šä¼ æœ¬æœº .bean æ–‡ä»¶ç»§ç»­ã€‚")
    st.code(str(BEANCOUNT_OUTPUT_DIR))
elif not all_files:
    st.warning("outputs/beancount ç›®å½•ä¸‹æœªå‘ç° .bean æ–‡ä»¶ï¼šä½ ä»ç„¶å¯ä»¥ä¸Šä¼ æœ¬æœº .bean æ–‡ä»¶ç»§ç»­ã€‚")

latest_source_tab_outputs, latest_source_tab_upload = st.tabs(["å·¥å…·å¯¼å‡º", "æœ¬åœ°æ–‡ä»¶"])

with latest_source_tab_outputs:
    if all_files:
        output_option_to_info = {
            info.name: info for info in all_files
        }
        selected_latest_output_option = st.selectbox(
            "AI å¤„ç†çš„è´¦å•ï¼ˆoutputs/beancountï¼‰",
            options=list(output_option_to_info.keys()),
            index=0,
            label_visibility="collapsed",
            key="ai_process_main_bill_outputs",
        )
        selected_latest_output_info = output_option_to_info[selected_latest_output_option]
    else:
        selected_latest_output_info = None
        st.info("å½“å‰ outputs/beancount æ²¡æœ‰å¯é€‰æ–‡ä»¶ã€‚")

with latest_source_tab_upload:
    uploaded_latest = st.file_uploader(
        "AI å¤„ç†çš„è´¦å•ï¼ˆä¸Šä¼  .beanï¼‰",
        type=["bean"],
        accept_multiple_files=False,
        help="ä¸Šä¼ åå°†ä¼˜å…ˆä½¿ç”¨ä¸Šä¼ æ–‡ä»¶ä½œä¸º AI å¤„ç†çš„è´¦å•ã€‚",
        label_visibility="collapsed",
        key="ai_process_main_bill_upload",
    )

selected_history_infos: list = []
uploaded_history_files: list = []
uploaded_account_definition = None

with st.expander("æ·»åŠ æ›´å¤šæ•°æ®", expanded=False):
    tab_reference, tab_accounts = st.tabs(["å†å²è´¦å•ï¼ˆå¯å¤šé€‰ï¼‰", "è´¦æˆ·å®šä¹‰ï¼ˆOpenè¯­å¥ï¼‰"])

    with tab_reference:
        selected_history_infos = []
        uploaded_history_files = st.file_uploader(
            "ä¸Šä¼ å†å²è´¦å•ï¼ˆå·²å¡«å……ï¼Œ.beanï¼Œå¯å¤šé€‰ï¼‰",
            type=["bean"],
            accept_multiple_files=True,
            help="å¯é€‰ï¼šç”¨äºç»™ AI æä¾›å·²å¡«å……è´¦æˆ·çš„ç¤ºä¾‹ã€‚",
            key="ai_process_history_upload",
            label_visibility="collapsed",
        ) or []

    with tab_accounts:
        uploaded_account_definition = st.file_uploader(
            "ä¸Šä¼ è´¦æˆ·å®šä¹‰ï¼ˆ.beanï¼‰",
            type=["bean"],
            accept_multiple_files=False,
            help="å¯é€‰ï¼šåŒ…å« open æŒ‡ä»¤çš„è´¦æˆ·è¡¨/ä¸»è´¦æœ¬ï¼ˆç”¨äºæä¾›å®Œæ•´è´¦æˆ·åˆ—è¡¨ï¼‰ã€‚",
            label_visibility="collapsed",
            key="ai_process_account_definition_upload",
        )

if uploaded_latest is not None:
    latest_summary = f"{uploaded_latest.name}ï¼ˆä¸Šä¼ ï¼‰"
elif selected_latest_output_info is not None:
    latest_summary = f"{selected_latest_output_info.name}ï¼ˆå·¥å…·å¯¼å‡ºï¼‰"
else:
    latest_summary = "æœªé€‰æ‹©"

history_total = len(selected_history_infos) + len(uploaded_history_files)

summary_parts = [f"AI å¤„ç†çš„è´¦å•ï¼š{latest_summary}"]
if history_total > 0:
    summary_parts.append(f"å†å²è´¦å•ï¼ˆå®Œæ•´æ•°æ®ï¼‰ï¼š{history_total}")
if uploaded_account_definition is not None:
    summary_parts.append("è´¦æˆ·å®šä¹‰ï¼šå·²ä¸Šä¼ ")
st.write(" ï½œ ".join(summary_parts))

st.divider()


st.subheader("Prompt")

with st.expander("å¯é€‰ï¼šé¢å¤–è§„åˆ™", expanded=False):
    extra_prompt = st.text_area(
        "é¢å¤–çš„è‡ªå®šä¹‰æŒ‡ç¤º",
        value="",
        height=150,
        placeholder=(
            "åœ¨è¿™é‡Œæ·»åŠ æ‚¨çš„è‡ªå®šä¹‰è§„åˆ™æˆ–æŒ‡ç¤ºï¼Œä¾‹å¦‚ï¼š\n\n"
            "- æ‰€æœ‰æ˜Ÿå·´å…‹çš„æ¶ˆè´¹éƒ½å½’ç±»åˆ° Expenses:Food:Cafe\n"
            "- äº¤é€šè´¹ç”¨è¶…è¿‡ 100 å…ƒçš„å½’ç±»åˆ° Expenses:Transport:LongDistance\n"
            "- ä¼˜å…ˆä½¿ç”¨ Expenses:Food:Restaurant è€Œä¸æ˜¯ Expenses:Food:Takeout"
        ),
        help="AI ä¼šåœ¨å¤„ç†æ—¶å‚è€ƒè¿™äº›è‡ªå®šä¹‰è§„åˆ™ã€‚ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤è§„åˆ™ã€‚",
        key="ai_process_extra_prompt",
        label_visibility="collapsed",
    )

with st.expander("é«˜çº§è®¾ç½®", expanded=False):
    st.warning("è½ç›˜ä¿å­˜çš„æ˜ å°„åŒ…å«çœŸå®é‡‘é¢ï¼Œä»…å»ºè®®åœ¨æœ¬æœºå¯ä¿¡ç¯å¢ƒä½¿ç”¨ã€‚")
    persist_map = st.checkbox(
        "è½ç›˜ä¿å­˜è„±æ•æ˜ å°„ï¼ˆåŒ…å«çœŸå®é‡‘é¢ï¼Œæ•æ„Ÿï¼‰",
        value=True,
        help="ä¿å­˜åˆ° outputs/mask_maps/{run_id}.jsonï¼Œç”¨äºé¡µé¢åˆ·æ–°/é‡å¯åä»å¯æ¢å¤é‡‘é¢ã€‚",
        key="ai_process_persist_mask_map",
    )
    masking_summary_placeholder = st.empty()
    masking_saved_path_placeholder = st.empty()

examples_per_transaction = st.slider(
    "æ¯ä¸ª TODO äº¤æ˜“çš„ç¤ºä¾‹æ•°é‡",
    min_value=1,
    max_value=5,
    value=3,
    help="ä¸ºæ¯ä¸ªå¾…å¡«å……è´¦æˆ·çš„äº¤æ˜“æä¾›å¤šå°‘ä¸ªç›¸ä¼¼çš„å†å²äº¤æ˜“ä½œä¸ºå‚è€ƒï¼ˆåŸºäº TF-IDF åŒ¹é…ï¼‰",
    key="ai_process_examples_per_transaction",
)

with st.spinner("æ­£åœ¨è¯»å–æ–‡ä»¶å¹¶æ„å»º Prompt..."):
    # 1) ç¡®å®šâ€œAI å¤„ç†çš„è´¦å•â€ï¼šä¸Šä¼ ä¼˜å…ˆï¼Œå…¶æ¬¡ outputs é€‰æ‹©
    latest_name: str | None = None
    latest_content: str | None = None

    if uploaded_latest is not None:
        raw = uploaded_latest.getvalue()
        latest_fingerprint = hashlib.sha1(raw or b"").hexdigest()
        latest_content = _decode_uploaded_beancount(raw)
        latest_name = uploaded_latest.name
        if latest_content is None:
            st.error(f"ä¸Šä¼ æ–‡ä»¶æ— æ³•ä»¥ UTF-8 è§£ç ï¼š{uploaded_latest.name}")
            st.stop()
    else:
        if selected_latest_output_info is None:
            st.error("è¯·å…ˆé€‰æ‹©æˆ–ä¸Šä¼ ä¸€ä¸ªâ€œAI å¤„ç†çš„è´¦å•ï¼ˆ.beanï¼‰â€ã€‚")
            st.stop()
        latest_name = selected_latest_output_info.name
        latest_fingerprint = (
            f"{selected_latest_output_info.name}:{selected_latest_output_info.mtime}:{selected_latest_output_info.size}"
        )
        latest_content = _cached_read_beancount_file(
            str(selected_latest_output_info.path),
            selected_latest_output_info.mtime,
        )
        if latest_content is None:
            st.error(f"è¯»å– AI å¤„ç†çš„è´¦å•å¤±è´¥ï¼š{selected_latest_output_info.name}")
            st.stop()

    reference_files: list[tuple[str, str]] = []
    reference_fingerprints: list[str] = []

    # 2) è¯»å–è´¦æˆ·å®šä¹‰æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    account_definition_content: str | None = None
    if uploaded_account_definition is not None:
        raw = uploaded_account_definition.getvalue()
        account_definition_content = _decode_uploaded_beancount(raw)
        if account_definition_content is None:
            st.warning(f"è´¦æˆ·å®šä¹‰æ–‡ä»¶æ— æ³•ä»¥ UTF-8 è§£ç ï¼Œå°†ä»å†å²äº¤æ˜“ä¸­æå–è´¦æˆ·ï¼š{uploaded_account_definition.name}")

    # 3) å†å²è´¦å•ï¼šoutputs å¤šé€‰ + æœ¬æœºä¸Šä¼ ï¼ˆä¸¤è€…åˆå¹¶ï¼‰
    for info in selected_history_infos:
        content = _cached_read_beancount_file(str(info.path), info.mtime)
        if content is None:
            st.error(f"è¯»å–å†å²è´¦å•å¤±è´¥ï¼Œå·²è·³è¿‡ï¼š{info.name}")
            continue
        reference_files.append((info.name, content))
        reference_fingerprints.append(f"{info.name}:{info.mtime}:{info.size}")

    for uf in uploaded_history_files:
        raw = uf.getvalue()
        reference_fingerprints.append(f"{uf.name}:{hashlib.sha1(raw or b'').hexdigest()}")
        decoded = _decode_uploaded_beancount(raw)
        if decoded is None:
            st.error(f"ä¸Šä¼ å†å²è´¦å•æ— æ³•ä»¥ UTF-8 è§£ç ï¼Œå·²è·³è¿‡ï¼š{uf.name}")
            continue
        reference_files.append((uf.name, decoded))

    # 4) é‡‘é¢è„±æ•ï¼ˆui_plan.md 2.7.2ï¼‰
    signature_payload = {
        "latest": {"name": str(latest_name), "fingerprint": latest_fingerprint},
        "refs": sorted(reference_fingerprints),
    }
    signature = json.dumps(signature_payload, sort_keys=True, ensure_ascii=False)
    run_id = hashlib.sha1(signature.encode("utf-8")).hexdigest()[:10]

    masker = AmountMasker(run_id=run_id)
    masked_latest_content = masker.mask_text(latest_content) or ""
    masked_reference_files: list[tuple[str, str]] = []
    for fn, fc in reference_files:
        masked_reference_files.append((fn, masker.mask_text(fc) or ""))

    amount_stats = masker.stats()
    masking_summary_placeholder.caption(
        f"é‡‘é¢è„±æ•ï¼š{amount_stats.tokens_total} å¤„ï¼ˆrun_id={amount_stats.run_id}ï¼‰"
    )

    saved_map_path: str | None = None
    if persist_map and amount_stats.tokens_total > 0:
        try:
            MASK_MAP_DIR.mkdir(parents=True, exist_ok=True)
            path = MASK_MAP_DIR / f"{amount_stats.run_id}.json"
            payload = {"run_id": amount_stats.run_id, "mapping": masker.mapping}
            path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
            saved_map_path = str(path)
            masking_saved_path_placeholder.caption("å·²ä¿å­˜è„±æ•æ˜ å°„ï¼š")
            masking_saved_path_placeholder.code(saved_map_path)
        except Exception as e:
            st.warning(f"è„±æ•æ˜ å°„è½ç›˜å¤±è´¥ï¼ˆä¸å½±å“æœ¬æ¬¡é¢„è§ˆï¼‰ï¼š{str(e)}")

    st.session_state["amount_masking"] = {
        "run_id": amount_stats.run_id,
        "tokens_total": amount_stats.tokens_total,
        "mapping": dict(masker.mapping),
        "saved_path": saved_map_path,
    }

    # 5) æ„å»º Promptï¼ˆä½¿ç”¨ v2 æ™ºèƒ½ä¼˜åŒ–ï¼‰
    prompt_masked, prompt_stats_v2 = build_smart_ai_prompt(
        latest_file_name=str(latest_name),
        latest_file_content=masked_latest_content,
        reference_files=masked_reference_files,
        examples_per_transaction=examples_per_transaction,
        account_definition_text=account_definition_content,
        extra_prompt=extra_prompt.strip() if extra_prompt else None,
    )
    prompt_real, _ = build_smart_ai_prompt(
        latest_file_name=str(latest_name),
        latest_file_content=latest_content,
        reference_files=reference_files,
        examples_per_transaction=examples_per_transaction,
        account_definition_text=account_definition_content,
        extra_prompt=extra_prompt.strip() if extra_prompt else None,
    )

show_real = st.checkbox(
    "æ˜¾ç¤ºçœŸå®é‡‘é¢ï¼ˆä»…æœ¬åœ°é¢„è§ˆï¼Œä¸ç”¨äºå‘é€ç»™ AIï¼‰",
    value=False,
    help="é»˜è®¤å±•ç¤ºè„±æ•ç‰ˆæœ¬ï¼›å‹¾é€‰åä¼šåœ¨é¡µé¢ä¸Šæ˜¾ç¤ºçœŸå®é‡‘é¢ã€‚",
    key="ai_process_show_real_amounts",
)

prompt_preview = prompt_real if show_real else prompt_masked
prompt_preview_label = "çœŸå®é‡‘é¢ | ä»…æœ¬åœ°é¢„è§ˆ" if show_real else "è„±æ•ç‰ˆæœ¬ | å°†å‘é€ç»™ AI"

prompt_stats = calculate_prompt_stats_v2(prompt_preview, prompt_stats_v2)
prompt_masked_hash = hashlib.sha1((prompt_masked or "").encode("utf-8")).hexdigest() if prompt_masked else ""

previous_prompt_stats = st.session_state.get("ai_process_prompt_stats_snapshot") or {}
previous_tokens = previous_prompt_stats.get("tokens")
previous_match_quality_pct = previous_prompt_stats.get("match_quality_pct")
previous_lines = previous_prompt_stats.get("lines")
previous_account_categories = previous_prompt_stats.get("account_categories")
previous_todo_transactions = previous_prompt_stats.get("todo_transactions")
previous_example_transactions = previous_prompt_stats.get("example_transactions")

match_quality_pct: float | None = None
try:
    match_quality_mean = prompt_stats.get("match_quality_mean")
    if match_quality_mean is not None:
        match_quality_pct = float(match_quality_mean) * 100.0
except Exception:
    match_quality_pct = None

estimated_prompt_tokens: int | None = None
try:
    from ai.config import AIConfigManager
    import litellm

    _ai_config = AIConfigManager().load_config()
    if _ai_config:
        token_count_model = _normalize_model_for_token_count(
            provider=_ai_config.get("provider"),
            model=_ai_config.get("model"),
        )
        if token_count_model:
            estimated_prompt_tokens = litellm.token_counter(
                model=token_count_model,
                messages=[{"role": "user", "content": prompt_preview}],
            )
except Exception:
    # ä»…ç”¨äº UI é¢„ä¼°ï¼Œä¸å½±å“é¡µé¢å…¶ä»–åŠŸèƒ½
    estimated_prompt_tokens = None

col1, col2, col3 = st.columns(3)
with col1:
    st.metric(
        "é¢„è®¡è¾“å…¥ Tokensï¼ˆå½“å‰é¢„è§ˆæ–‡æœ¬ï¼‰",
        f"{estimated_prompt_tokens:,}" if estimated_prompt_tokens is not None else "â€”",
        delta=_format_metric_delta(estimated_prompt_tokens, previous_tokens)
        if estimated_prompt_tokens is not None
        else None,
    )
with col2:
    st.metric(
        "è¡Œæ•°",
        f"{prompt_stats.get('lines', 0):,}",
        delta=_format_metric_delta(prompt_stats.get("lines", 0), previous_lines),
    )
with col3:
    _match_quality_help = (
        "åŒ¹é…è´¨é‡ = æ‰€æœ‰ TODO äº¤æ˜“çš„ Top1 ç›¸ä¼¼åº¦å‡å€¼ Ã— 100%ã€‚\n"
        "ç›¸ä¼¼åº¦æ¥è‡ª TF-IDF + ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆåŸºäºäº¤æ˜“æè¿°ï¼‰ï¼ŒTop1 è¡¨ç¤ºæœ€ç›¸ä¼¼çš„ä¸€æ¡å†å²äº¤æ˜“ã€‚\n"
        "èŒƒå›´ 0%~100%ï¼Œè¶Šé«˜è¡¨ç¤ºç¤ºä¾‹è¶Šè´´è¿‘ï¼›æ²¡æœ‰å†å²ç¤ºä¾‹æˆ–æ²¡æœ‰ TODO æ—¶æ˜¾ç¤º â€”ã€‚"
    )
    st.metric(
        "åŒ¹é…è´¨é‡",
        f"{match_quality_pct:.1f}%" if match_quality_pct is not None else "â€”",
        delta=_format_metric_delta(match_quality_pct, previous_match_quality_pct)
        if match_quality_pct is not None
        else None,
        help=_match_quality_help,
    )

col4, col5, col6 = st.columns(3)
with col4:
    st.metric(
        "å¯ç”¨è´¦æˆ·",
        prompt_stats.get("account_categories", 0),
        delta=_format_metric_delta(prompt_stats.get("account_categories", 0), previous_account_categories),
    )
with col5:
    st.metric(
        "TODO äº¤æ˜“",
        prompt_stats.get("todo_transactions", 0),
        delta=_format_metric_delta(prompt_stats.get("todo_transactions", 0), previous_todo_transactions),
    )
with col6:
    st.metric(
        "ç¤ºä¾‹äº¤æ˜“",
        prompt_stats.get("example_transactions", 0),
        delta=_format_metric_delta(prompt_stats.get("example_transactions", 0), previous_example_transactions),
    )

# å¤§å°æç¤º
if estimated_prompt_tokens is not None:
    if estimated_prompt_tokens > 25_000:
        st.warning(f"âš ï¸ Prompt é¢„è®¡ {estimated_prompt_tokens:,} tokensï¼ˆè¶…è¿‡ 25,000ï¼‰ï¼Œå¯èƒ½å½±å“ AI å¤„ç†æ•ˆæœæˆ–æˆæœ¬ã€‚")
else:
    if prompt_stats.get("chars", 0) > 100_000:
        st.warning("âš ï¸ Prompt è¶…è¿‡ 100KBï¼Œå¯èƒ½å½±å“ AI å¤„ç†æ•ˆæœã€‚")
    # tokens æ— æ³•ä¼°ç®—æ—¶ï¼Œä¸æ˜¾ç¤º successï¼Œé¿å…å’Œä¸Šæ–¹æŒ‡æ ‡é‡å¤

with st.expander(f"Prompt é¢„è§ˆ | {prompt_preview_label}", expanded=False):
    st.code(prompt_preview, language="markdown")

st.session_state["ai_process_prompt_stats_snapshot"] = {
    "tokens": int(estimated_prompt_tokens) if estimated_prompt_tokens is not None else None,
    "chars": int(prompt_stats.get("chars", 0) or 0),
    "lines": int(prompt_stats.get("lines", 0) or 0),
    "match_quality_pct": float(match_quality_pct) if match_quality_pct is not None else None,
    "account_categories": int(prompt_stats.get("account_categories", 0) or 0),
    "todo_transactions": int(prompt_stats.get("todo_transactions", 0) or 0),
    "example_transactions": int(prompt_stats.get("example_transactions", 0) or 0),
}

st.divider()


st.subheader("å‘é€åˆ° AI")

redaction_check_result = check_prompt_redaction(prompt_masked or "")
redaction_checked_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
if prompt_masked:
    _checked_at_suffix = f" ï½œ æœ€æ–°æ£€æŸ¥æ—¶é—´ï¼ˆæœ¬æœºï¼‰ï¼š{redaction_checked_at}"
    if redaction_check_result.error_message:
        st.info(f"Prompt è„±æ•æ£€æŸ¥ï¼šæœªçŸ¥ï¼ˆæ£€æŸ¥å¤±è´¥ï¼š{redaction_check_result.error_message}ï¼‰{_checked_at_suffix}")
    elif redaction_check_result.ok:
        st.success(f"Prompt è„±æ•æ£€æŸ¥ï¼šé€šè¿‡ï¼ˆæœªå‘ç°ç–‘ä¼¼æœªè„±æ•é‡‘é¢ï¼‰{_checked_at_suffix}")
    else:
        st.warning(f"Prompt è„±æ•æ£€æŸ¥ï¼šç–‘ä¼¼æœªå®Œå…¨è„±æ•ï¼ˆå‘½ä¸­ {redaction_check_result.total_issues} å¤„ï¼‰{_checked_at_suffix}")
        st.caption("æç¤ºï¼šè¿™å¯èƒ½æ˜¯ç¨‹åºçš„ bugï¼Œæ²¡æœ‰è„±æ•å®Œå…¨ã€‚ä½ ä»å¯ç»§ç»­å‘é€ï¼Œä½†è¯·ç¡®è®¤é£é™©ã€‚")
        with st.expander("æŸ¥çœ‹å‘½ä¸­ç¤ºä¾‹ï¼ˆå·²éšè—é‡‘é¢æ•°å­—ï¼‰", expanded=False):
            if redaction_check_result.sample_lines:
                st.code("\n".join(redaction_check_result.sample_lines))
            else:
                st.write("ï¼ˆæš‚æ— ç¤ºä¾‹ï¼‰")
else:
    st.info(f"Prompt è„±æ•æ£€æŸ¥ï¼šâ€”ï¼ˆæš‚æ— å¯å‘é€çš„ Promptï¼‰ ï½œ æœ€æ–°æ£€æŸ¥æ—¶é—´ï¼ˆæœ¬æœºï¼‰ï¼š{redaction_checked_at}")

# æ£€æŸ¥ AI é…ç½®
from ai.config import AIConfigManager
from ai.service import AIService
from config.secrets import (
    MASTER_PASSWORD_ENV,
    MasterPasswordNotSetError,
    PlaintextSecretFoundError,
    SecretDecryptionError,
)

ai_config_manager = AIConfigManager()

if not ai_config_manager.config_present():
    st.error("âŒ å°šæœªé…ç½® AIï¼Œè¯·å…ˆå‰å¾€ã€ŒAI é…ç½®ã€é¡µé¢è¿›è¡Œé…ç½®")
    st.stop()

try:
    config = ai_config_manager.load_config_strict()
except MasterPasswordNotSetError:
    st.error(f"ğŸ”’ AI é…ç½®å·²åŠ å¯†ï¼Œä½†æœªè®¾ç½®ç¯å¢ƒå˜é‡ {MASTER_PASSWORD_ENV}ï¼Œæ— æ³•è§£é”ã€‚")
    st.caption("è¯·åœ¨å¯åŠ¨ Streamlit å‰è®¾ç½®è¯¥ç¯å¢ƒå˜é‡ï¼Œç„¶åé‡å¯åº”ç”¨ã€‚")
    st.stop()
except PlaintextSecretFoundError as e:
    st.error(f"âŒ {str(e)}")
    st.caption("è¯·å‰å¾€ã€ŒAI é…ç½®ã€é¡µé¢åˆ é™¤åé‡æ–°è®¾ç½®ã€‚")
    st.stop()
except SecretDecryptionError as e:
    st.error(f"âŒ {str(e)}")
    st.caption("è¯·ç¡®è®¤ä¸»å¯†ç æ˜¯å¦æ­£ç¡®ï¼›è‹¥å¿˜è®°ä¸»å¯†ç ï¼Œåªèƒ½åˆ é™¤é…ç½®åé‡æ–°è®¾ç½®ã€‚")
    st.stop()
except Exception as e:
    st.error(f"âŒ AI é…ç½®åŠ è½½å¤±è´¥ï¼š{str(e)}")
    st.stop()

st.info(f"ğŸ“¡ å½“å‰ä½¿ç”¨ï¼š{config['provider']} | {config['model']}")

# å‘é€æŒ‰é’®ï¼ˆç‚¹å‡»åè¿›å…¥â€œæ„å›¾å‘é€â€çŠ¶æ€ï¼Œé¿å…åœ¨ dialog/é‡è·‘æ—¶é‡å¤è§¦å‘ï¼‰
send_button_clicked = st.button(
    "ğŸ¤– å‘é€åˆ° AI å¤„ç†",
    disabled=not prompt_masked,
    use_container_width=True,
    type="primary",
)

if send_button_clicked:
    st.session_state["ai_process_send_intent"] = True
    st.session_state["ai_process_force_send"] = False
    st.session_state["ai_process_send_prompt_hash"] = prompt_masked_hash


@st.dialog("è„±æ•æ£€æŸ¥æç¤º")
def _redaction_confirm_dialog() -> None:
    st.warning("æ£€æµ‹åˆ°å¯èƒ½æœªå®Œå…¨è„±æ•çš„é‡‘é¢ç‰‡æ®µã€‚")
    st.write("è¿™å¯èƒ½æ˜¯ç¨‹åºçš„ bugï¼Œæ²¡æœ‰è„±æ•å®Œå…¨ã€‚ä½ ä»ç„¶å¯ä»¥ç»§ç»­å‘é€ï¼Œä½†è¯·ç¡®è®¤é£é™©ã€‚")
    if redaction_check_result.sample_lines:
        with st.expander("å‘½ä¸­ç¤ºä¾‹ï¼ˆå·²éšè—é‡‘é¢æ•°å­—ï¼‰", expanded=False):
            st.code("\n".join(redaction_check_result.sample_lines))

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ä»ç„¶å‘é€", type="primary", use_container_width=True):
            st.session_state["ai_process_force_send"] = True
            st.rerun()
    with col2:
        if st.button("å–æ¶ˆ", use_container_width=True):
            st.session_state["ai_process_send_intent"] = False
            st.session_state["ai_process_force_send"] = False
            st.session_state.pop("ai_process_send_prompt_hash", None)
            st.rerun()


should_send = bool(st.session_state.get("ai_process_send_intent"))
force_send = bool(st.session_state.get("ai_process_force_send"))
pending_hash = st.session_state.get("ai_process_send_prompt_hash")

if should_send:
    if pending_hash and pending_hash != prompt_masked_hash:
        st.warning("âš ï¸ Prompt å·²å‘ç”Ÿå˜åŒ–ï¼šè¯·é‡æ–°ç‚¹å‡»å‘é€ã€‚")
        st.session_state["ai_process_send_intent"] = False
        st.session_state["ai_process_force_send"] = False
        st.session_state.pop("ai_process_send_prompt_hash", None)
    elif (not redaction_check_result.ok) and (not force_send):
        _redaction_confirm_dialog()
    else:
        st.session_state["ai_process_send_intent"] = False
        st.session_state["ai_process_force_send"] = False
        st.session_state.pop("ai_process_send_prompt_hash", None)

    ai_service = AIService(ai_config_manager)

    with st.status("æ­£åœ¨è°ƒç”¨ AI...", expanded=True) as status:
        # è°ƒç”¨ AIï¼ˆä½¿ç”¨è„±æ•åçš„ promptï¼‰
        call_stats = ai_service.call_completion(prompt_masked)

        # ä¿å­˜ç»“æœåˆ° session_state
        st.session_state["ai_result"] = {
            "stats": call_stats,
            "latest_name": latest_name,
            "prompt_masked_hash": prompt_masked_hash,
        }

        if call_stats.success:
            status.update(label="âœ… AI å¤„ç†å®Œæˆ", state="complete")
        else:
            status.update(label="âŒ AI è°ƒç”¨å¤±è´¥", state="error")

# æ˜¾ç¤º AI ç»“æœï¼ˆåŸºäº session_stateï¼Œè€Œä¸æ˜¯ send_buttonï¼‰
if "ai_result" in st.session_state:
    result = st.session_state["ai_result"]
    stats = result["stats"]
    latest_name = result["latest_name"]
    result_prompt_hash = result.get("prompt_masked_hash") or ""

    if result_prompt_hash and prompt_masked_hash and result_prompt_hash != prompt_masked_hash:
        st.warning("âš ï¸ ä½ å·²æ›´æ”¹æ–‡ä»¶/å‚æ•°ï¼šå½“å‰ Prompt ä¸ä¸Šæ¬¡å‘é€ç»™ AI çš„ Prompt å¯èƒ½ä¸ä¸€è‡´ï¼Œå»ºè®®é‡æ–°å‘é€ã€‚")

    st.subheader("AI ç»“æœ")

    if stats.success:
        with st.spinner("æ­£åœ¨å¯¹è´¦..."):
            reconcile_report = reconcile_beancount(
                before_text=masked_latest_content,  # å‘é€å‰çš„æœ€æ–°è´¦å•ï¼ˆè„±æ•ç‰ˆæœ¬ï¼‰
                after_text=stats.response,  # AI è¿”å›çš„è„±æ•æ–‡æœ¬
            )

        tab_stats, tab_response, tab_reconcile, tab_restore = st.tabs(
            ["è°ƒç”¨ç»Ÿè®¡", "è¿”å›å†…å®¹ï¼ˆè„±æ•ï¼‰", "å¯¹è´¦", "æ¢å¤é‡‘é¢ / ä¸‹è½½"]
        )

        with tab_stats:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("è€—æ—¶", f"{stats.total_time:.2f} ç§’")
            with col2:
                st.metric("é‡è¯•æ¬¡æ•°", stats.retry_count)
            with col3:
                st.metric("è¾“å…¥ Tokens", f"{stats.prompt_tokens:,}")
            with col4:
                st.metric("è¾“å‡º Tokens", f"{stats.completion_tokens:,}")

            st.write(f"æ€» Tokensï¼š{stats.total_tokens:,}")

        with tab_response:
            st.code(stats.response, language="beancount")

        with tab_reconcile:
            if reconcile_report.is_valid:
                st.success("âœ… å¯¹è´¦é€šè¿‡ï¼šäº¤æ˜“å®Œæ•´æ— ç¯¡æ”¹")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å‘é€å‰äº¤æ˜“æ•°", reconcile_report.total_before)
                with col2:
                    st.metric("è¿”å›åäº¤æ˜“æ•°", reconcile_report.total_after)
            else:
                st.error("âŒ å¯¹è´¦å¤±è´¥ï¼šå‘ç°å¼‚å¸¸")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å‘é€å‰äº¤æ˜“æ•°", reconcile_report.total_before)
                with col2:
                    st.metric("è¿”å›åäº¤æ˜“æ•°", reconcile_report.total_after)
                with col3:
                    st.metric("å·®å¼‚æ•°", len(reconcile_report.missing) + len(reconcile_report.added))

                if reconcile_report.error_message:
                    st.warning(f"é”™è¯¯ä¿¡æ¯ï¼š{reconcile_report.error_message}")

                if reconcile_report.missing:
                    with st.expander(f"âš ï¸ ç¼ºå¤±çš„äº¤æ˜“ï¼ˆ{len(reconcile_report.missing)} ç¬”ï¼‰", expanded=True):
                        for txn in reconcile_report.missing:
                            st.code(
                                f"{txn.date} * \"{txn.description}\"\n"
                                f"  é‡‘é¢: {', '.join(txn.amounts)}\n"
                                f"  è´¦æˆ·: {', '.join(txn.accounts)}",
                                language="text",
                            )

                if reconcile_report.added:
                    with st.expander(f"âš ï¸ å¼‚å¸¸æ–°å¢çš„äº¤æ˜“ï¼ˆ{len(reconcile_report.added)} ç¬”ï¼‰", expanded=True):
                        for txn in reconcile_report.added:
                            st.code(
                                f"{txn.date} * \"{txn.description}\"\n"
                                f"  é‡‘é¢: {', '.join(txn.amounts)}\n"
                                f"  è´¦æˆ·: {', '.join(txn.accounts)}",
                                language="text",
                            )

                if reconcile_report.tampered:
                    with st.expander(f"âš ï¸ è¢«ç¯¡æ”¹çš„äº¤æ˜“ï¼ˆ{len(reconcile_report.tampered)} ç¬”ï¼‰", expanded=True):
                        for info in reconcile_report.tampered:
                            st.markdown(f"**åŸå§‹ï¼š** {info.before.date} * \"{info.before.description}\"")
                            st.markdown(f"**ä¿®æ”¹åï¼š** {info.after.date} * \"{info.after.description}\"")
                            st.markdown(f"**åŸå› ï¼š** {info.reason}")
                            st.divider()

                st.warning("âš ï¸ å¯¹è´¦å¤±è´¥å¯èƒ½å¯¼è‡´æ•°æ®ä¸å®Œæ•´ï¼Œè¯·è°¨æ…å¤„ç†ã€‚")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ”„ é‡æ–°å‘é€ç»™ AI", use_container_width=True):
                        st.rerun()
                with col2:
                    st.button("âœï¸ æ‰‹åŠ¨ä¿®å¤", use_container_width=True, disabled=True, help="åŠŸèƒ½å¼€å‘ä¸­")

        with tab_restore:
            if not reconcile_report.is_valid:
                st.warning("å¯¹è´¦æœªé€šè¿‡ï¼šé»˜è®¤ä¸å…è®¸æ¢å¤é‡‘é¢ã€‚ä½ å¯ä»¥é€‰æ‹©å¿½ç•¥ç»§ç»­ï¼ˆé£é™©è‡ªæ‹…ï¼‰ã€‚")

            ignore_reconcile_failure = st.checkbox(
                "âš ï¸ å¿½ç•¥å¯¹è´¦å¤±è´¥å¹¶ç»§ç»­ï¼ˆé£é™©ï¼‰",
                value=bool(st.session_state.get("ignore_reconcile_failure", False)),
                key="ignore_reconcile_failure",
            )

            restore_disabled = not reconcile_report.is_valid and not ignore_reconcile_failure
            if st.button("ğŸ”“ æ¢å¤é‡‘é¢", use_container_width=True, disabled=restore_disabled):
                try:
                    masking_info = st.session_state.get("amount_masking")
                    if not masking_info or not masking_info.get("mapping"):
                        st.error("âŒ æœªæ‰¾åˆ°è„±æ•æ˜ å°„ï¼Œæ— æ³•æ¢å¤é‡‘é¢")
                    else:
                        restore_masker = AmountMasker(run_id=masking_info["run_id"])
                        restore_masker.mapping = masking_info["mapping"]
                        restored_content = restore_masker.unmask_text(stats.response)

                        st.success("âœ… é‡‘é¢æ¢å¤æˆåŠŸ")

                        with st.spinner("æ­£åœ¨å¯¹è´¦..."):
                            reconciler = BeancountReconciler()
                            filling_report = reconciler.reconcile_account_filling(
                                original_text=latest_content,
                                restored_text=restored_content,
                            )

                        if filling_report.is_valid:
                            st.success("âœ… é‡‘é¢æ¢å¤å¯¹è´¦é€šè¿‡")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("æ€»äº¤æ˜“æ•°", filling_report.total_transactions)
                            with col2:
                                st.metric("åŒ¹é…æˆåŠŸ", filling_report.matched_transactions)
                        else:
                            st.error(f"âŒ é‡‘é¢æ¢å¤å¯¹è´¦å¤±è´¥ï¼š{filling_report.error_message}")

                        with st.expander("ğŸ“„ å¤„ç†ç»“æœï¼ˆçœŸå®é‡‘é¢ï¼‰", expanded=True):
                            st.code(restored_content, language="beancount")

                        st.download_button(
                            label="ğŸ’¾ ä¸‹è½½å¤„ç†åçš„ Beancount æ–‡ä»¶",
                            data=restored_content,
                            file_name=f"ai_processed_{latest_name}",
                            mime="text/plain",
                            use_container_width=True,
                        )
                except Exception as e:
                    st.error(f"âŒ æ¢å¤é‡‘é¢å¤±è´¥ï¼š{str(e)}")

    else:
        # AI è°ƒç”¨å¤±è´¥
        st.error(f"é”™è¯¯ä¿¡æ¯ï¼š{stats.error_message}")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("è€—æ—¶", f"{stats.total_time:.2f} ç§’")
        with col2:
            st.metric("é‡è¯•æ¬¡æ•°", stats.retry_count)
