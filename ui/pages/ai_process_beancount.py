"""
AI æ™ºèƒ½å¤„ç† Beancount è´¦å•ï¼ˆui_plan.md 2.7.1ï¼‰

åŠŸèƒ½ï¼š
- è‡ªåŠ¨é€‰æ‹©æœ€æ–° Beancount æ–‡ä»¶ï¼ˆoutputs/beancountï¼‰
- æ”¯æŒå¤šé€‰å†å²æ–‡ä»¶ä½œä¸ºå‚è€ƒåº“
- æ„å»ºå¹¶é¢„è§ˆ Promptï¼ˆæœ¬æ¬¡ä¸åšåç«¯ AI è°ƒç”¨ï¼‰
"""

from __future__ import annotations

from pathlib import Path
import hashlib
import json
import re

import streamlit as st

from constants import BEANCOUNT_OUTPUT_DIR, PROJECT_ROOT
from utils.beancount_file_manager import scan_beancount_files
from utils.beancount_file_manager import read_beancount_file
from utils.amount_masking import AmountMasker
from utils.prompt_builder_v2 import build_smart_ai_prompt, calculate_prompt_stats_v2
from utils.beancount_validator import reconcile_beancount, BeancountReconciler


st.set_page_config(page_title="AI å¤„ç† Beancount", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– AI æ™ºèƒ½å¤„ç† Beancount è´¦å•")
st.caption("é€‰æ‹©æœ€æ–°è´¦å•å’Œå†å²å‚è€ƒæ–‡ä»¶ï¼Œæ„å»º AI å¤„ç† Promptï¼Œå¹¶å‘é€ç»™ AI å¡«å……æ¶ˆè´¹è´¦æˆ·ã€‚")
st.divider()

_DATE_RANGE_RE = re.compile(r"(?P<start>\d{8})_(?P<end>\d{8})")
MASK_MAP_DIR = PROJECT_ROOT / "outputs" / "mask_maps"


def _format_yyyymmdd(value: str) -> str | None:
    if not value or len(value) != 8:
        return None
    yyyy, mm, dd = value[:4], value[4:6], value[6:8]
    return f"{yyyy}-{mm}-{dd}"


def _format_date_range_from_filename(filename: str) -> str:
    match = _DATE_RANGE_RE.search(filename or "")
    if not match:
        return "æœªçŸ¥"
    start = _format_yyyymmdd(match.group("start"))
    end = _format_yyyymmdd(match.group("end"))
    if start and end:
        return f"{start} è‡³ {end}"
    return "æœªçŸ¥"


def _format_size_bytes(size: int) -> str:
    try:
        size_f = float(size)
    except Exception:
        return "æœªçŸ¥"
    if size_f < 1024:
        return f"{int(size_f)} B"
    size_f /= 1024
    if size_f < 1024:
        return f"{size_f:.1f} KB"
    size_f /= 1024
    return f"{size_f:.1f} MB"


def _decode_uploaded_beancount(raw: bytes) -> str | None:
    if raw is None:
        return None
    try:
        return raw.decode("utf-8")
    except UnicodeDecodeError:
        try:
            return raw.decode("utf-8-sig")
        except Exception:
            return None


@st.cache_data(show_spinner=False)
def _cached_read_beancount_file(path_str: str, mtime: float) -> str | None:
    # mtime ä½œä¸ºç¼“å­˜ key çš„ä¸€éƒ¨åˆ†ï¼Œæ–‡ä»¶å˜æ›´æ—¶è‡ªåŠ¨å¤±æ•ˆ
    return read_beancount_file(Path(path_str))


all_files = scan_beancount_files(BEANCOUNT_OUTPUT_DIR) if BEANCOUNT_OUTPUT_DIR.exists() else []


st.subheader("ğŸ“‚ æ–‡ä»¶é€‰æ‹©")

if not BEANCOUNT_OUTPUT_DIR.exists():
    st.warning("æœªæ‰¾åˆ° outputs/beancount ç›®å½•ï¼šä½ ä»ç„¶å¯ä»¥ä¸Šä¼ æœ¬æœº .bean æ–‡ä»¶ç»§ç»­ã€‚")
    st.code(str(BEANCOUNT_OUTPUT_DIR))
elif not all_files:
    st.warning("outputs/beancount ç›®å½•ä¸‹æœªå‘ç° .bean æ–‡ä»¶ï¼šä½ ä»ç„¶å¯ä»¥ä¸Šä¼ æœ¬æœº .bean æ–‡ä»¶ç»§ç»­ã€‚")

st.markdown("#### âœ… æœ€æ–°è´¦å•ï¼ˆé»˜è®¤é€‰æ‹©æœ€æ–°ï¼Œä¹Ÿå¯æ‰‹åŠ¨é€‰æ‹©/ä¸Šä¼ ï¼‰")
latest_source_tab_outputs, latest_source_tab_upload = st.tabs(["ä» outputs é€‰æ‹©", "ä»æœ¬æœºä¸Šä¼ "])

with latest_source_tab_outputs:
    if all_files:
        output_option_to_info = {
            f"{info.name} ({info.format_size()} | {info.format_date_range()})": info
            for info in all_files
        }
        selected_latest_output_option = st.selectbox(
            "é€‰æ‹©æœ€æ–°è´¦å•ï¼ˆæ¥è‡ª outputs/beancountï¼‰",
            options=list(output_option_to_info.keys()),
            index=0,
        )
        selected_latest_output_info = output_option_to_info[selected_latest_output_option]
    else:
        selected_latest_output_info = None
        st.info("å½“å‰ outputs/beancount æ²¡æœ‰å¯é€‰æ–‡ä»¶ã€‚")

with latest_source_tab_upload:
    uploaded_latest = st.file_uploader(
        "ä¸Šä¼ æœ€æ–°è´¦å•ï¼ˆ.beanï¼‰",
        type=["bean"],
        accept_multiple_files=False,
        help="é€‰æ‹©ä½ æœ¬æœºä¸Šçš„ .bean æ–‡ä»¶ä½œä¸ºâ€œæœ€æ–°è´¦å•â€ã€‚ä¸Šä¼ åå°†ä¼˜å…ˆä½¿ç”¨ä¸Šä¼ æ–‡ä»¶ã€‚",
    )

st.markdown("#### ğŸ“š å†å²è´¦å•ï¼ˆå¯é€‰å¤šä¸ªä½œä¸ºå‚è€ƒï¼Œä¹Ÿå¯ä»æœ¬æœºä¸Šä¼ ï¼‰")
history_source_tab_outputs, history_source_tab_upload = st.tabs(["ä» outputs å¤šé€‰", "ä»æœ¬æœºæ‰¹é‡ä¸Šä¼ "])

with history_source_tab_outputs:
    history_candidates = []
    if all_files:
        history_candidates = list(all_files)
    if selected_latest_output_info is not None:
        history_candidates = [f for f in history_candidates if f.name != selected_latest_output_info.name]

    if not history_candidates:
        selected_history_infos = []
        st.info("å½“å‰ outputs/beancount æ²¡æœ‰å¯é€‰çš„å†å²æ–‡ä»¶ã€‚")
    else:
        history_option_to_info = {
            f"{info.name} ({info.format_size()} | {info.format_date_range()})": info
            for info in history_candidates
        }
        selected_history_options = st.multiselect(
            "é€‰æ‹©å†å²è´¦å•æ–‡ä»¶ï¼ˆæ¥è‡ª outputs/beancountï¼‰",
            options=list(history_option_to_info.keys()),
            default=[],
            help="å¯é€‰æ‹©å¤šä¸ªå†å² Beancount æ–‡ä»¶ä½œä¸ºå‚è€ƒï¼Œå¸®åŠ© AI å­¦ä¹ ä½ çš„è´¦æˆ·å‘½åä¹ æƒ¯ã€‚",
        )
        selected_history_infos = [history_option_to_info[o] for o in selected_history_options]

with history_source_tab_upload:
    uploaded_history_files = st.file_uploader(
        "ä¸Šä¼ å†å²è´¦å•ï¼ˆå¯å¤šé€‰ .beanï¼‰",
        type=["bean"],
        accept_multiple_files=True,
        help="ä¸Šä¼ çš„æ–‡ä»¶å°†è¢«åŠ å…¥å‚è€ƒåº“ï¼ˆå†å²è´¦å•ï¼‰ã€‚",
    ) or []

st.divider()

st.markdown("#### ğŸ“‹ è´¦æˆ·å®šä¹‰æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œæ¨èï¼‰")
uploaded_account_definition = st.file_uploader(
    "ä¸Šä¼ è´¦æˆ·å®šä¹‰æ–‡ä»¶ï¼ˆåŒ…å« open æŒ‡ä»¤çš„ .bean æ–‡ä»¶ï¼‰",
    type=["bean"],
    accept_multiple_files=False,
    help=(
        "**æ¨èä¸Šä¼ **ï¼šåŒ…å«æ‰€æœ‰è´¦æˆ· open æŒ‡ä»¤çš„ Beancount æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ä¸»è´¦æœ¬æ–‡ä»¶ï¼‰ã€‚\n\n"
        "ç¤ºä¾‹æ ¼å¼ï¼š\n"
        "```\n"
        "2024-01-01 open Expenses:Food:Restaurant\n"
        "2024-01-01 open Expenses:Transport:Taxi\n"
        "```\n\n"
        "å¦‚æœä¸ä¸Šä¼ ï¼Œå°†ä»å†å²äº¤æ˜“æ–‡ä»¶ä¸­æå–è´¦æˆ·ï¼ˆåªèƒ½è·å¾—å·²ä½¿ç”¨è¿‡çš„è´¦æˆ·ï¼‰ã€‚"
    ),
)

st.divider()


st.subheader("âš™ï¸ Prompt æ„å»ºé€‰é¡¹")

# ç¤ºä¾‹æ•°é‡é…ç½®
examples_per_transaction = st.slider(
    "æ¯ä¸ª TODO äº¤æ˜“çš„ç¤ºä¾‹æ•°é‡",
    min_value=1,
    max_value=5,
    value=3,
    help="ä¸ºæ¯ä¸ªå¾…å¡«å……è´¦æˆ·çš„äº¤æ˜“æä¾›å¤šå°‘ä¸ªç›¸ä¼¼çš„å†å²äº¤æ˜“ä½œä¸ºå‚è€ƒï¼ˆåŸºäº TF-IDF åŒ¹é…ï¼‰",
)

# è‡ªå®šä¹‰ Prompt
extra_prompt = st.text_area(
    "é¢å¤–çš„è‡ªå®šä¹‰æŒ‡ç¤ºï¼ˆå¯é€‰ï¼‰",
    value="",
    height=150,
    placeholder=(
        "åœ¨è¿™é‡Œæ·»åŠ æ‚¨çš„è‡ªå®šä¹‰è§„åˆ™æˆ–æŒ‡ç¤ºï¼Œä¾‹å¦‚ï¼š\n\n"
        "- æ‰€æœ‰æ˜Ÿå·´å…‹çš„æ¶ˆè´¹éƒ½å½’ç±»åˆ° Expenses:Food:Cafe\n"
        "- äº¤é€šè´¹ç”¨è¶…è¿‡ 100 å…ƒçš„å½’ç±»åˆ° Expenses:Transport:LongDistance\n"
        "- ä¼˜å…ˆä½¿ç”¨ Expenses:Food:Restaurant è€Œä¸æ˜¯ Expenses:Food:Takeout"
    ),
    help="AI ä¼šåœ¨å¤„ç†æ—¶å‚è€ƒè¿™äº›è‡ªå®šä¹‰è§„åˆ™ã€‚ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤è§„åˆ™ã€‚",
)

st.divider()


st.subheader("ğŸ“ Prompt é¢„è§ˆ")
with st.spinner("æ­£åœ¨è¯»å–æ–‡ä»¶å¹¶æ„å»º Prompt..."):
    # 1) ç¡®å®šâ€œæœ€æ–°è´¦å•â€ï¼šä¸Šä¼ ä¼˜å…ˆï¼Œå…¶æ¬¡ outputs é€‰æ‹©
    latest_name: str | None = None
    latest_content: str | None = None
    latest_display_size: str | None = None
    latest_display_range: str | None = None

    if uploaded_latest is not None:
        raw = uploaded_latest.getvalue()
        latest_fingerprint = hashlib.sha1(raw or b"").hexdigest()
        latest_content = _decode_uploaded_beancount(raw)
        latest_name = uploaded_latest.name
        latest_display_size = _format_size_bytes(len(raw or b""))
        latest_display_range = _format_date_range_from_filename(uploaded_latest.name)
        if latest_content is None:
            st.error(f"ä¸Šä¼ æ–‡ä»¶æ— æ³•ä»¥ UTF-8 è§£ç ï¼š{uploaded_latest.name}")
            st.stop()
    else:
        if selected_latest_output_info is None:
            st.error("è¯·å…ˆé€‰æ‹©æˆ–ä¸Šä¼ ä¸€ä¸ªâ€œæœ€æ–°è´¦å•ï¼ˆ.beanï¼‰â€ã€‚")
            st.stop()
        latest_name = selected_latest_output_info.name
        latest_fingerprint = f"{selected_latest_output_info.name}:{selected_latest_output_info.mtime}:{selected_latest_output_info.size}"
        latest_content = _cached_read_beancount_file(str(selected_latest_output_info.path), selected_latest_output_info.mtime)
        latest_display_size = selected_latest_output_info.format_size()
        latest_display_range = selected_latest_output_info.format_date_range()
        if latest_content is None:
            st.error(f"è¯»å–æœ€æ–°è´¦å•å¤±è´¥ï¼š{selected_latest_output_info.name}")
            st.stop()

    reference_files: list[tuple[str, str]] = []
    reference_fingerprints: list[str] = []

    # 2) è¯»å–è´¦æˆ·å®šä¹‰æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    account_definition_content: str | None = None
    if uploaded_account_definition is not None:
        raw = uploaded_account_definition.getvalue()
        account_definition_content = _decode_uploaded_beancount(raw)
        if account_definition_content is None:
            st.warning(f"è´¦æˆ·å®šä¹‰æ–‡ä»¶æ— æ³•ä»¥ UTF-8 è§£ç ï¼Œå°†ä»å†å²äº¤æ˜“ä¸­æå–è´¦æˆ·ï¼š{uploaded_account_definition.name}")

    # 3) å†å²è´¦å•ï¼šoutputs å¤šé€‰ + æœ¬æœºä¸Šä¼ ï¼ˆä¸¤è€…åˆå¹¶ï¼‰
    for info in selected_history_infos:
        content = _cached_read_beancount_file(str(info.path), info.mtime)
        if content is None:
            st.error(f"è¯»å–å†å²è´¦å•å¤±è´¥ï¼Œå·²è·³è¿‡ï¼š{info.name}")
            continue
        reference_files.append((info.name, content))
        reference_fingerprints.append(f"{info.name}:{info.mtime}:{info.size}")

    for uf in uploaded_history_files:
        raw = uf.getvalue()
        reference_fingerprints.append(f"{uf.name}:{hashlib.sha1(raw or b'').hexdigest()}")
        decoded = _decode_uploaded_beancount(raw)
        if decoded is None:
            st.error(f"ä¸Šä¼ å†å²è´¦å•æ— æ³•ä»¥ UTF-8 è§£ç ï¼Œå·²è·³è¿‡ï¼š{uf.name}")
            continue
        reference_files.append((uf.name, decoded))

    # 3) é‡‘é¢è„±æ•ï¼ˆui_plan.md 2.7.2ï¼‰
    # - é»˜è®¤å¯¹â€œæœ€æ–°è´¦å• + æ‰€æœ‰å†å²å‚è€ƒè´¦å•â€ç»Ÿä¸€è„±æ•ï¼Œä¿è¯ Prompt ä¸­ä¸å‡ºç°çœŸå®é‡‘é¢
    # - è„±æ•æ˜ å°„ä¼šå­˜å…¥ session_stateï¼ˆå¯é€‰è½ç›˜ï¼‰ï¼Œä¸ºåç»­ 2.7.3ï¼ˆAI è¿”å›åæ¢å¤é‡‘é¢ï¼‰åšå‡†å¤‡
    signature_payload = {
        "latest": {"name": str(latest_name), "fingerprint": latest_fingerprint},
        "refs": sorted(reference_fingerprints),
    }
    signature = json.dumps(signature_payload, sort_keys=True, ensure_ascii=False)
    run_id = hashlib.sha1(signature.encode("utf-8")).hexdigest()[:10]

    masker = AmountMasker(run_id=run_id)
    masked_latest_content = masker.mask_text(latest_content) or ""
    masked_reference_files: list[tuple[str, str]] = []
    for fn, fc in reference_files:
        masked_reference_files.append((fn, masker.mask_text(fc) or ""))

    amount_stats = masker.stats()
    st.caption(f"é‡‘é¢è„±æ•ï¼š{amount_stats.tokens_total} å¤„ï¼ˆrun_id={amount_stats.run_id}ï¼‰")

    persist_map = st.checkbox(
        "è½ç›˜ä¿å­˜è„±æ•æ˜ å°„ï¼ˆåŒ…å«çœŸå®é‡‘é¢ï¼Œæ•æ„Ÿï¼‰",
        value=True,
        help="ä¿å­˜åˆ° outputs/mask_maps/{run_id}.jsonï¼Œç”¨äºé¡µé¢åˆ·æ–°/é‡å¯åä»å¯æ¢å¤é‡‘é¢ã€‚",
    )
    saved_map_path: str | None = None
    if persist_map and amount_stats.tokens_total > 0:
        try:
            MASK_MAP_DIR.mkdir(parents=True, exist_ok=True)
            path = MASK_MAP_DIR / f"{amount_stats.run_id}.json"
            payload = {"run_id": amount_stats.run_id, "mapping": masker.mapping}
            path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
            saved_map_path = str(path)
            st.caption("å·²ä¿å­˜è„±æ•æ˜ å°„ï¼š")
            st.code(saved_map_path)
        except Exception as e:
            st.warning(f"è„±æ•æ˜ å°„è½ç›˜å¤±è´¥ï¼ˆä¸å½±å“æœ¬æ¬¡é¢„è§ˆï¼‰ï¼š{str(e)}")

    st.session_state["amount_masking"] = {
        "run_id": amount_stats.run_id,
        "tokens_total": amount_stats.tokens_total,
        "mapping": dict(masker.mapping),
        "saved_path": saved_map_path,
    }

    # æ„å»º Promptï¼ˆä½¿ç”¨ v2 æ™ºèƒ½ä¼˜åŒ–ï¼‰
    prompt_masked, prompt_stats_v2 = build_smart_ai_prompt(
        latest_file_name=str(latest_name),
        latest_file_content=masked_latest_content,
        reference_files=masked_reference_files,
        examples_per_transaction=examples_per_transaction,
        account_definition_text=account_definition_content,
        extra_prompt=extra_prompt.strip() if extra_prompt else None,
    )
    prompt_real, _ = build_smart_ai_prompt(
        latest_file_name=str(latest_name),
        latest_file_content=latest_content,
        reference_files=reference_files,
        examples_per_transaction=examples_per_transaction,
        account_definition_text=account_definition_content,
        extra_prompt=extra_prompt.strip() if extra_prompt else None,
    )

show_real = st.checkbox(
    "æ˜¾ç¤ºçœŸå®é‡‘é¢ï¼ˆä»…æœ¬åœ°é¢„è§ˆï¼Œä¸ç”¨äºå‘é€ç»™ AIï¼‰",
    value=False,
    help="é»˜è®¤å±•ç¤ºè„±æ•ç‰ˆæœ¬ï¼›å‹¾é€‰åä¼šåœ¨é¡µé¢ä¸Šæ˜¾ç¤ºçœŸå®é‡‘é¢ã€‚",
)
prompt = prompt_real if show_real else prompt_masked

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
stats = calculate_prompt_stats_v2(prompt, prompt_stats_v2)

# æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("å­—ç¬¦æ•°", f"{stats.get('chars', 0):,}")
with col2:
    st.metric("è¡Œæ•°", f"{stats.get('lines', 0):,}")
with col3:
    st.metric("æ–‡ä»¶æ•°", stats.get('files', 0))

col4, col5, col6 = st.columns(3)
with col4:
    st.metric("å¯ç”¨è´¦æˆ·", stats.get('account_categories', 0))
with col5:
    st.metric("TODO äº¤æ˜“", stats.get('todo_transactions', 0))
with col6:
    st.metric("ç¤ºä¾‹äº¤æ˜“", stats.get('example_transactions', 0))

# å¤§å°æç¤º
if stats.get("chars", 0) > 100_000:
    st.warning("âš ï¸ Prompt è¶…è¿‡ 100KBï¼Œå¯èƒ½å½±å“ AI å¤„ç†æ•ˆæœã€‚")
else:
    st.success(f"âœ… Prompt å¤§å°ï¼š{stats.get('chars', 0):,} å­—ç¬¦ï¼ˆå·²ä¼˜åŒ–ï¼‰")

with st.expander("ğŸ“ é¢„è§ˆ Promptï¼ˆå³ä¸Šè§’å¯å¤åˆ¶ï¼‰", expanded=False):
    st.code(prompt, language="markdown")

st.divider()


st.subheader("ğŸš€ å‘é€åˆ° AI å¤„ç†")

# æ£€æŸ¥ AI é…ç½®
from ai.config import AIConfigManager
from ai.service import AIService

ai_config_manager = AIConfigManager()

if not ai_config_manager.config_exists():
    st.error("âŒ å°šæœªé…ç½® AIï¼Œè¯·å…ˆå‰å¾€ã€ŒAI é…ç½®ã€é¡µé¢è¿›è¡Œé…ç½®")
    st.stop()

config = ai_config_manager.load_config()
if config:
    st.info(f"ğŸ“¡ å½“å‰ä½¿ç”¨ï¼š{config['provider']} | {config['model']}")
else:
    st.error("âŒ AI é…ç½®åŠ è½½å¤±è´¥")
    st.stop()

# å‘é€æŒ‰é’®
send_button = st.button(
    "ğŸ¤– å‘é€åˆ° AI å¤„ç†",
    disabled=not prompt_masked,
    use_container_width=True,
    type="primary",
)

if send_button:
    ai_service = AIService(ai_config_manager)

    with st.status("æ­£åœ¨è°ƒç”¨ AI...", expanded=True) as status:
        import time as time_module

        start_time = time_module.time()

        # è°ƒç”¨ AIï¼ˆä½¿ç”¨è„±æ•åçš„ promptï¼‰
        stats = ai_service.call_completion(prompt_masked)

        # ä¿å­˜ç»“æœåˆ° session_state
        st.session_state["ai_result"] = {
            "stats": stats,
            "latest_name": latest_name,
        }

        if stats.success:
            status.update(label="âœ… AI å¤„ç†å®Œæˆ", state="complete")
        else:
            status.update(label="âŒ AI è°ƒç”¨å¤±è´¥", state="error")

# æ˜¾ç¤º AI ç»“æœï¼ˆåŸºäº session_stateï¼Œè€Œä¸æ˜¯ send_buttonï¼‰
if "ai_result" in st.session_state:
    result = st.session_state["ai_result"]
    stats = result["stats"]
    latest_name = result["latest_name"]

    if stats.success:
        # å±•ç¤ºç»Ÿè®¡ä¿¡æ¯
        st.subheader("ğŸ“Š è°ƒç”¨ç»Ÿè®¡")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("è€—æ—¶", f"{stats.total_time:.2f} ç§’")
        with col2:
            st.metric("é‡è¯•æ¬¡æ•°", stats.retry_count)
        with col3:
            st.metric("è¾“å…¥ Tokens", f"{stats.prompt_tokens:,}")
        with col4:
            st.metric("è¾“å‡º Tokens", f"{stats.completion_tokens:,}")

        st.caption(f"æ€» Tokens: {stats.total_tokens:,}")

        # å±•ç¤º AI è¿”å›å†…å®¹ï¼ˆè„±æ•ç‰ˆæœ¬ï¼‰
        st.subheader("ğŸ“„ AI å¤„ç†ç»“æœï¼ˆè„±æ•ç‰ˆæœ¬ï¼‰")
        st.code(stats.response, language="beancount")

        # å¯¹è´¦åŠŸèƒ½ï¼ˆui_plan.md 2.7.4ï¼‰
        st.divider()
        st.subheader("ğŸ” å¯¹è´¦æ£€æŸ¥")
        st.caption("æ£€æŸ¥ AI è¿”å›çš„å†…å®¹æ˜¯å¦å®Œæ•´ã€æ˜¯å¦æœ‰ç¯¡æ”¹")

        with st.spinner("æ­£åœ¨å¯¹è´¦..."):
            # è°ƒç”¨å¯¹è´¦å‡½æ•°
            reconcile_report = reconcile_beancount(
                    before_text=masked_latest_content,  # å‘é€å‰çš„æœ€æ–°è´¦å•ï¼ˆè„±æ•ç‰ˆæœ¬ï¼‰
                    after_text=stats.response           # AI è¿”å›çš„è„±æ•æ–‡æœ¬
                )

            # å±•ç¤ºå¯¹è´¦ç»“æœ
            if reconcile_report.is_valid:
                st.success("âœ… å¯¹è´¦é€šè¿‡ï¼äº¤æ˜“å®Œæ•´æ— ç¯¡æ”¹")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å‘é€å‰äº¤æ˜“æ•°", reconcile_report.total_before)
                with col2:
                    st.metric("è¿”å›åäº¤æ˜“æ•°", reconcile_report.total_after)
            else:
                st.error("âŒ å¯¹è´¦å¤±è´¥ï¼å‘ç°å¼‚å¸¸")

                # å±•ç¤ºç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å‘é€å‰äº¤æ˜“æ•°", reconcile_report.total_before)
                with col2:
                    st.metric("è¿”å›åäº¤æ˜“æ•°", reconcile_report.total_after)
                with col3:
                    st.metric("å·®å¼‚æ•°", len(reconcile_report.missing) + len(reconcile_report.added))

                # å±•ç¤ºè¯¦ç»†å·®å¼‚
                if reconcile_report.error_message:
                    st.warning(f"é”™è¯¯ä¿¡æ¯ï¼š{reconcile_report.error_message}")

                if reconcile_report.missing:
                    with st.expander(f"âš ï¸ ç¼ºå¤±çš„äº¤æ˜“ï¼ˆ{len(reconcile_report.missing)} ç¬”ï¼‰", expanded=True):
                        for txn in reconcile_report.missing:
                            st.code(
                                f"{txn.date} * \"{txn.description}\"\n"
                                f"  é‡‘é¢: {', '.join(txn.amounts)}\n"
                                f"  è´¦æˆ·: {', '.join(txn.accounts)}",
                                language="text"
                            )

                if reconcile_report.added:
                    with st.expander(f"âš ï¸ å¼‚å¸¸æ–°å¢çš„äº¤æ˜“ï¼ˆ{len(reconcile_report.added)} ç¬”ï¼‰", expanded=True):
                        for txn in reconcile_report.added:
                            st.code(
                                f"{txn.date} * \"{txn.description}\"\n"
                                f"  é‡‘é¢: {', '.join(txn.amounts)}\n"
                                f"  è´¦æˆ·: {', '.join(txn.accounts)}",
                                language="text"
                            )

                if reconcile_report.tampered:
                    with st.expander(f"âš ï¸ è¢«ç¯¡æ”¹çš„äº¤æ˜“ï¼ˆ{len(reconcile_report.tampered)} ç¬”ï¼‰", expanded=True):
                        for info in reconcile_report.tampered:
                            st.markdown(f"**åŸå§‹ï¼š** {info.before.date} * \"{info.before.description}\"")
                            st.markdown(f"**ä¿®æ”¹åï¼š** {info.after.date} * \"{info.after.description}\"")
                            st.markdown(f"**åŸå› ï¼š** {info.reason}")
                            st.divider()

                # æä¾›å¤„ç†é€‰é¡¹
                st.warning("âš ï¸ å»ºè®®ï¼šå¯¹è´¦å¤±è´¥å¯èƒ½å¯¼è‡´æ•°æ®ä¸å®Œæ•´ï¼Œè¯·è°¨æ…å¤„ç†")
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ”„ é‡æ–°å‘é€ç»™ AI", use_container_width=True):
                        st.rerun()
                with col2:
                    st.button("âœï¸ æ‰‹åŠ¨ä¿®å¤", use_container_width=True, disabled=True, help="åŠŸèƒ½å¼€å‘ä¸­")
                with col3:
                    ignore_and_continue = st.checkbox("âš ï¸ å¿½ç•¥å¹¶ç»§ç»­ï¼ˆé£é™©ï¼‰", value=False)

            st.divider()

            # æ¢å¤é‡‘é¢
            st.subheader("ğŸ”“ æ¢å¤çœŸå®é‡‘é¢")
            st.caption("å°† AI è¿”å›çš„è„±æ•é‡‘é¢æ¢å¤ä¸ºçœŸå®é‡‘é¢")

            # å¦‚æœå¯¹è´¦å¤±è´¥ä¸”ç”¨æˆ·æœªé€‰æ‹©å¿½ç•¥ï¼Œç¦ç”¨æ¢å¤æŒ‰é’®
            restore_disabled = not reconcile_report.is_valid and not st.session_state.get("ignore_reconcile_failure", False)
            if not reconcile_report.is_valid:
                if st.session_state.get("ignore_reconcile_failure", False) or locals().get("ignore_and_continue", False):
                    st.session_state["ignore_reconcile_failure"] = True
                    restore_disabled = False

            if st.button("ğŸ”“ æ¢å¤é‡‘é¢", use_container_width=True, disabled=restore_disabled):
                try:
                    # ä» session_state è·å–è„±æ•æ˜ å°„
                    masking_info = st.session_state.get("amount_masking")
                    if not masking_info or not masking_info.get("mapping"):
                        st.error("âŒ æœªæ‰¾åˆ°è„±æ•æ˜ å°„ï¼Œæ— æ³•æ¢å¤é‡‘é¢")
                    else:
                        # åˆ›å»º masker å¹¶æ¢å¤é‡‘é¢
                        restore_masker = AmountMasker(run_id=masking_info["run_id"])
                        restore_masker.mapping = masking_info["mapping"]

                        restored_content = restore_masker.unmask_text(stats.response)

                        st.success("âœ… é‡‘é¢æ¢å¤æˆåŠŸï¼")

                        # ç¬¬äºŒæ¬¡å¯¹è´¦ï¼šæ£€æŸ¥è´¦æˆ·å¡«å……æ˜¯å¦æ­£ç¡®
                        st.divider()
                        st.subheader("ğŸ” é‡‘é¢æ¢å¤å¯¹è´¦")
                        st.caption("æ£€æŸ¥æ¢å¤é‡‘é¢åçš„æ—¥æœŸã€é‡‘é¢ã€æè¿°æ˜¯å¦ä¸åŸå§‹ä¸€è‡´")

                        with st.spinner("æ­£åœ¨å¯¹è´¦..."):
                            # è·å–åŸå§‹æœªè„±æ•çš„å†…å®¹
                            original_content = latest_content

                            # è°ƒç”¨è´¦æˆ·å¡«å……å¯¹è´¦å‡½æ•°
                            reconciler = BeancountReconciler()
                            filling_report = reconciler.reconcile_account_filling(
                                original_text=original_content,
                                restored_text=restored_content
                            )

                        if filling_report.is_valid:
                            st.success("âœ… é‡‘é¢æ¢å¤å¯¹è´¦é€šè¿‡")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("æ€»äº¤æ˜“æ•°", filling_report.total_transactions)
                            with col2:
                                st.metric("åŒ¹é…æˆåŠŸ", filling_report.matched_transactions)
                        else:
                            st.error(f"âŒ é‡‘é¢æ¢å¤å¯¹è´¦å¤±è´¥ï¼š{filling_report.error_message}")

                        st.divider()

                        st.subheader("ğŸ“„ AI å¤„ç†ç»“æœï¼ˆçœŸå®é‡‘é¢ï¼‰")
                        st.code(restored_content, language="beancount")

                        # æä¾›ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ’¾ ä¸‹è½½å¤„ç†åçš„ Beancount æ–‡ä»¶",
                            data=restored_content,
                            file_name=f"ai_processed_{latest_name}",
                            mime="text/plain",
                            use_container_width=True,
                        )

                except Exception as e:
                    st.error(f"âŒ æ¢å¤é‡‘é¢å¤±è´¥ï¼š{str(e)}")

    else:
        # AI è°ƒç”¨å¤±è´¥
        st.error(f"é”™è¯¯ä¿¡æ¯ï¼š{stats.error_message}")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("è€—æ—¶", f"{stats.total_time:.2f} ç§’")
        with col2:
            st.metric("é‡è¯•æ¬¡æ•°", stats.retry_count)
